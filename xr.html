<!DOCTYPE html>
<html lang="en">
	<head>
		<title>WebXR + LLM Test</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
        <style>
            body {
                font-family: Arial, sans-serif;
                padding: 20px;
            }
            .container {
                max-width: 600px;
                margin: auto;
            }
            input, button, p {
                margin-top: 10px;
                width: 10%;
                padding: 10px;
                box-sizing: border-box;
            }
            #microphoneButton {
                position: fixed;
                bottom: 60px;
                left: 50%;
                transform: translateX(-50%);
                z-index: 100;
                font-size: 10px;
                cursor: pointer;
            }
            .listening {
                background-color: red;
                color: white;
            }
        </style>
	</head>
	<body>

		<div id="info">
			<a href="https://threejs.org" target="_blank" rel="noopener">three.js</a> AR Test<br/>(Chrome Android 81+)
		</div>

        <button id="microphoneButton"><img id="microphoneIcon" src="microphone.png" alt="Microphone" style="width: 100px"/></button>

		<script type="importmap">
			{
				"imports": {
					"three": "https://unpkg.com/three@latest/build/three.module.js",
                    "three/addons/": "https://unpkg.com/three@latest/examples/jsm/"
				}
			}
		</script>

		<script type="module">

			import * as THREE from 'three';
			import { ARButton } from 'three/addons/webxr/ARButton.js';

            // Button
            let recognition;
            let listening = false;
            let startTimestamp;

            const button = document.getElementById('microphoneButton');
            const listeningIndicator = document.getElementById('listeningIndicator');
            const microphoneIcon = document.getElementById('microphoneIcon');

            const transcription = document.getElementById('transcription'); // Get the transcription display element

            const startRecognition = () => {
                if ('webkitSpeechRecognition' in window) {
                    listening = true;
                    recognition = new webkitSpeechRecognition();
                    recognition.continuous = false;
                    recognition.interimResults = false;

                    recognition.onstart = function() {
                        listeningIndicator.style.display = 'block';
                        microphoneIcon.style.filter = 'invert(20%) sepia(100%) saturate(7500%) hue-rotate(0deg) brightness(100%) contrast(101%)';
                        transcription.textContent = ''; // Clear previous transcription
                    };

                    recognition.onresult = function(event) {
                        const transcript = event.results[0][0].transcript;
                        transcription.textContent = transcript; // Display the transcribed text
                        speak(transcript);
                    };

                    recognition.onerror = function(event) {
                        console.error('Speech recognition error', event.error);
                        resetState();
                    };

                    recognition.onend = function() {
                        resetState();
                    };

                    recognition.start();
                } else {
                    alert('Your browser does not support speech recognition.');
                }
            };

            const stopRecognition = () => {
                if (recognition && listening) {
                    recognition.stop();
                    listening = false;
                }
            };

            const resetState = () => {
                listeningIndicator.style.display = 'none';
                microphoneIcon.style.filter = '';
                listening = false;
            };

            const speak = (text) => {
                let utterance = new SpeechSynthesisUtterance(text);
                window.speechSynthesis.speak(utterance);
            };

            const handleStart = (event) => {
                event.preventDefault();
                if (!listening) {
                    startTimestamp = event.timeStamp;
                    startRecognition();
                }
            };

            const handleEnd = (event) => {
                event.preventDefault();
                if (listening && (event.timeStamp - startTimestamp > 100)) {
                    stopRecognition();
                }
            };

            button.addEventListener('mousedown', handleStart, false);
            button.addEventListener('mouseup', handleEnd, false);
            button.addEventListener('touchstart', handleStart, false);
            button.addEventListener('touchend', handleEnd, false);
            button.addEventListener('mouseleave', stopRecognition, false);

			let container;
			let camera, scene, renderer;
			let controller;

			let reticle;

			let hitTestSource = null;
			let hitTestSourceRequested = false;

			init();
			animate();

			function init() {

				container = document.createElement( 'div' );
				document.body.appendChild( container );

				scene = new THREE.Scene();

				camera = new THREE.PerspectiveCamera( 70, window.innerWidth / window.innerHeight, 0.01, 20 );

				const light = new THREE.HemisphereLight( 0xffffff, 0xbbbbff, 3 );
				light.position.set( 0.5, 1, 0.25 );
				scene.add( light );

				//

				renderer = new THREE.WebGLRenderer( { antialias: true, alpha: true } );
				renderer.setPixelRatio( window.devicePixelRatio );
				renderer.setSize( window.innerWidth, window.innerHeight );
				renderer.xr.enabled = true;
				container.appendChild( renderer.domElement );

				//

				document.body.appendChild( ARButton.createButton( renderer, { requiredFeatures: [ 'hit-test' ] } ) );

				// Load the earth texture
                const textureLoader = new THREE.TextureLoader();
                const earthTexture = textureLoader.load('https://unpkg.com/three-globe@2.30.0/example/img/earth-blue-marble.jpg');

                // Create SphereGeometry for the globe
                const geometry = new THREE.SphereGeometry(0.1, 32, 32);

                let currentGlobe = null; // Variable to store the current globe

				function onSelect() {

					if (reticle.visible) {
                        // Remove the existing globe if it exists
                        if (currentGlobe) {
                            scene.remove(currentGlobe);
                        }

                        // Use the loaded texture for the material
                        const material = new THREE.MeshBasicMaterial({ map: earthTexture });
                        
                        // Adjust the size of the globe
                        const largerGeometry = new THREE.SphereGeometry(0.2, 256, 256); // Make the globe larger

                        const mesh = new THREE.Mesh(largerGeometry, material);
                        reticle.matrix.decompose(mesh.position, mesh.quaternion, mesh.scale);
                        scene.add(mesh);

                        // Adjust the position to be 4 feet (approximately 1.2 meters) above the selected surface
                        mesh.position.y += 1.2;

                        currentGlobe = mesh; // Store the new globe
                    }

				}

				controller = renderer.xr.getController( 0 );
				controller.addEventListener( 'select', onSelect );
				scene.add( controller );

				reticle = new THREE.Mesh(
					new THREE.RingGeometry( 0.15, 0.2, 32 ).rotateX( - Math.PI / 2 ),
					new THREE.MeshBasicMaterial()
				);
				reticle.matrixAutoUpdate = false;
				reticle.visible = false;
				scene.add( reticle );

				window.addEventListener( 'resize', onWindowResize );

			}

			function onWindowResize() {
				camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();
				renderer.setSize( window.innerWidth, window.innerHeight );
			}

			function animate() {
				renderer.setAnimationLoop( render );
			}

			function render( timestamp, frame ) {

				if ( frame ) {

					const referenceSpace = renderer.xr.getReferenceSpace();
					const session = renderer.xr.getSession();

					if ( hitTestSourceRequested === false ) {

						session.requestReferenceSpace( 'viewer' ).then( function ( referenceSpace ) {

							session.requestHitTestSource( { space: referenceSpace } ).then( function ( source ) {

								hitTestSource = source;

							} );

						} );

						session.addEventListener( 'end', function () {

							hitTestSourceRequested = false;
							hitTestSource = null;

						} );

						hitTestSourceRequested = true;

					}

					if ( hitTestSource ) {

						const hitTestResults = frame.getHitTestResults( hitTestSource );

						if ( hitTestResults.length ) {

							const hit = hitTestResults[ 0 ];

							reticle.visible = true;
							reticle.matrix.fromArray( hit.getPose( referenceSpace ).transform.matrix );

						} else {

							reticle.visible = false;

						}

					}

				}

				renderer.render( scene, camera );

			}

		</script>
	</body>
</html>